import OpenAI from "openai";

export type ChatMessage = { role: "system" | "user" | "assistant"; content: string };

export interface AIProvider {
  embed(texts: string[]): Promise<number[][]>;
  chat(opts: { model: string; messages: ChatMessage[]; temperature?: number }): Promise<string>;
}

export function getProvider() : AIProvider {
  const provider = process.env.AI_PROVIDER ?? "openai";
  if (provider !== "openai") {
    // Заготовка: можно подключить OpenRouter/Anthropic/Groq
    throw new Error(`AI_PROVIDER ${provider} not implemented yet`);
  }
  const client = new OpenAI({ apiKey: process.env.OPENAI_API_KEY! });

  return {
    async embed(texts: string[]) {
      const model = process.env.AI_EMBED_MODEL ?? "text-embedding-3-large";
      const res = await client.embeddings.create({
        model,
        input: texts,
      });
      return res.data.map(d => d.embedding as unknown as number[]);
    },
    async chat({ model, messages, temperature }) {
      const res = await client.chat.completions.create({
        model,
        messages,
        temperature: temperature ?? 0.7,
      });
      return res.choices[0]?.message?.content ?? "";
    },
  };
}
